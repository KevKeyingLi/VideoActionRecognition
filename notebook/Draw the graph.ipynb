{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from scipy import io as sio\n",
    "import numpy as np\n",
    "import time\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "BASE_DIR = '/Users/baroc/repos/VideoActionRecognition/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(BASE_DIR+'src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    def __init__(self, start, end, fps, videoname):\n",
    "        self.id = 0;\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.fps = fps\n",
    "        self.videoname = videoname \n",
    "        self.trajectories = []\n",
    "#         self.features = dict()\n",
    "#         # contains six lists of what features are avaible. This info can be used to compute the histogram\n",
    "#         # use numpy.histogram or scipy.stat.histogram\n",
    "#         self.features['mean_x'] = []\n",
    "#         self.features['mean_y'] = []\n",
    "#         self.features['traj_idx'] = []\n",
    "#         self.features['hog'] = []\n",
    "#         self.features['hof'] = []\n",
    "#         self.features['mbh'] = []\n",
    "        self.histogram = []\n",
    "        self.allOverLapLabels = dict() # a dictionary of {overlapping label: [lb_str_t, lb_end_t], overlap}\n",
    "        self.labels = [] # only the labels that are considered positive.\n",
    "        # add groud truth\n",
    "        \n",
    "    def add_trajectory(self, traj): # call this when you need it\n",
    "        self.trajectories.append(traj)\n",
    "    def add_label(self, tlabel_info, overlap): # \n",
    "        # add to allOverLapLabels\n",
    "        # tlabel_info = ['video_validation_0000051', [67.5, 75.9], 'Billiards']\n",
    "        if tlabel_info[2] in self.allOverLapLabels:\n",
    "            self.allOverLapLabels[tlabel_info[2]].append([tlabel_info[1],overlap])\n",
    "        else:\n",
    "            self.allOverLapLabels[tlabel_info[2]] = [[tlabel_info[1],overlap]]\n",
    "#             self.allOverLapLabels[tlabel_info[2]].append([tlabel_info[1],overlap])\n",
    "        # add to labels\n",
    "        if overlap>0.5:\n",
    "            self.labels.append(tlabel_info[2]) # it is possible that there are multiple same label for a node.\n",
    "    def record_feature(self): \n",
    "        ###########\n",
    "        # this method currently counts all existence, and don't take into account the coverage of each trajectory\n",
    "        # if need the coverage info in the future, can simply modify to:\n",
    "        # self.feature_cnt['mean_x'].append([traj.mean_x,traj.coverage])\n",
    "        \n",
    "        if len(self.features['traj_idx']) == 0:\n",
    "            raise ValueError(\"record_features not usable. Because no features. Use add_feature in loop instead. \")\n",
    "        for traj in self.trajectories:\n",
    "            self.features['mean_x'].append(traj.mean_x)\n",
    "            self.features['mean_y'].append(traj.mean_y)\n",
    "            self.features['traj_idx'].append(traj.traj_idx)\n",
    "            self.features['hog'].append(traj.hog)\n",
    "            self.features['hof'].append(traj.hof)\n",
    "            self.features['mbh'].append(traj.mbh)\n",
    "        return\n",
    "    \n",
    "    def add_feature(self, mean_x, mean_y, traj, hog, hof, mbh):\n",
    "        # this function computes and adds the histogram of the 16,000 features, \n",
    "        # and adds the mean_x mean_y information if necessary\n",
    "        hist_hog = np.histogram(hog,4000,(0,4000))[0]\n",
    "        hist_hof = np.histogram(hof,4000,(0,4000))[0]\n",
    "        hist_mbh = np.histogram(mbh,4000,(0,4000))[0]\n",
    "        hist_traj = np.histogram(traj,4000,(0,4000))[0]\n",
    "        self.histogram = np.concatenate((hist_traj, hist_hog, hist_hof, hist_mbh))\n",
    "#         self.mean_x = mean_x\n",
    "#         self.mean_y = mean_y\n",
    "    def set_id(self, idx):\n",
    "        self.id = idx\n",
    "\n",
    "class Trajectory:\n",
    "    def __init__(self, frame_num, mean_x, mean_y, traj_idx, hog, hof, mbh, coverage):\n",
    "        self.frame_num  = frame_num \n",
    "        self.mean_x  = mean_x \n",
    "        self.mean_y  = mean_y \n",
    "        self.traj_idx  = traj_idx \n",
    "        self.hog  = hog\n",
    "        self.hof  = hof\n",
    "        self.mbh  = mbh\n",
    "        self.coverage = coverage # The portion of trajectory included in the window\n",
    "\n",
    "\n",
    "def computeOverlap(window_start, window_end, label_start, label_end):\n",
    "    \n",
    "    if window_start < label_end and label_start < window_end:\n",
    "        # overlap\n",
    "        if window_start > label_start:\n",
    "            l_start = window_start\n",
    "            s_start = label_start\n",
    "        else:\n",
    "            l_start = label_start\n",
    "            s_start = window_start \n",
    "        if window_end > label_end:\n",
    "            l_end = window_end\n",
    "            s_end = label_end\n",
    "        else:\n",
    "            l_end = label_end\n",
    "            s_end = window_end \n",
    "        return (s_end-l_start)/(l_end - s_start)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def generateNode(video_info, video_tLabelList, FEATURE_DIR, traj_coverage_threashold = 0.5,windowSize = 150, stepSize = 100):# by frame, default value comes from the Thumos report.\n",
    "    # generate nodes for a video, return a list of Node\n",
    "    # before calling this function, require to find the video_info and video_tLabelList for this video. \n",
    "    video_name = video_info[0][0]\n",
    "    if 'validation' in video_name:\n",
    "        duration_frame = video_info[8][0][0]\n",
    "        fps = float(video_info[9][0][0])\n",
    "    elif 'test' in video_name:\n",
    "        duration_frame = int(video_info[5][0][0]*video_info[7][0][0])\n",
    "        fps = float(video_info[7][0][0])\n",
    "    # read in the file and form a list of trajectory features\n",
    "    with open(FEATURE_DIR+video_name+'.txt','r') as f:\n",
    "        # later: make the directory as a variable\n",
    "        trajs = f.readlines()\n",
    "    trajs = [x.split('\\t')[:-1] for x in trajs]\n",
    "    ####################for debug\n",
    "#     trajs = trajs[:308001]\n",
    "    #####################\n",
    "    traj_start_idx = 0 # the index of the first trajectory of each window\n",
    "    next_traj_idx = 0\n",
    "    next_traj_set = False\n",
    "    # form a list of window start point. \n",
    "    frame_step_list = range(0, duration_frame, stepSize)# The start of frame? \n",
    "    # Do you also need to consider the window to be full length, not truncated on the last few steps. \n",
    "    # Note that in the dataset, there is no trajectory ending on the last frame, so we don't use duration_frame+1\n",
    "    window_start_frame = 0\n",
    "    window_end_frame = 0\n",
    "    node_list = []\n",
    "    \n",
    "    for i in range(len(frame_step_list) ):# For each window\n",
    "        if(frame_step_list[i] + windowSize < duration_frame):\n",
    "            # Both start and end are inclusive\n",
    "            window_start_frame = frame_step_list[i]\n",
    "            window_end_frame = frame_step_list[i] + windowSize - 1\n",
    "        elif frame_step_list[i] + windowSize < duration_frame+stepSize:\n",
    "            # The last window\n",
    "            window_start_frame = frame_step_list[i]\n",
    "            window_end_frame = duration_frame\n",
    "        else:\n",
    "            # Extra windows\n",
    "            break\n",
    "#         print window_start_frame,window_end_frame\n",
    "        \n",
    "        traj_start_idx = next_traj_idx \n",
    "        # next_traj_idx is used to record the start trajectory of next window, when constructing the current node\n",
    "        next_traj_set = False\n",
    "        # initialize node\n",
    "        traj = trajs[traj_start_idx] # Current trajectory\n",
    "        end_frame = int(traj[0])\n",
    "        start_frame = end_frame-15+1\n",
    "        new_node = Node(window_start_frame, window_end_frame, fps, video_name)\n",
    "        traj_len = 15\n",
    "        # feature list\n",
    "        features = dict()\n",
    "        features['mean_x'] = []\n",
    "        features['mean_y'] = []\n",
    "        features['traj'] = []\n",
    "        features['hog'] = []\n",
    "        features['hof'] = []\n",
    "        features['mbh'] = []\n",
    "        # Add trajectories, \n",
    "        while(traj_start_idx<len(trajs) and (window_start_frame<=end_frame<=window_end_frame or window_start_frame<=start_frame<=window_end_frame)):\n",
    "            coverage = 1.0\n",
    "            traj = trajs[traj_start_idx] # Current trajectory\n",
    "            end_frame = int(traj[0])\n",
    "            start_frame = end_frame-15+1\n",
    "#             print \"start and end\"+ str(start_frame)+' , '+str(end_frame)\n",
    "            if not next_traj_set and i+1 < len(frame_step_list) and end_frame >= frame_step_list[i+1]:\n",
    "                next_traj_idx = traj_start_idx\n",
    "                next_traj_set = True\n",
    "            if(end_frame<= window_end_frame and window_start_frame<=start_frame):\n",
    "                pass\n",
    "            # this trajectory is totally in the window\n",
    "            #     coverage = 1.0\n",
    "            elif start_frame < window_start_frame and window_start_frame <= end_frame: # first few trajs\n",
    "                # Only the tail of the trajectory is in the window\n",
    "                coverage = float(end_frame - window_start_frame + 1)/traj_len\n",
    "#                 print coverage\n",
    "            elif window_end_frame >= start_frame and end_frame>window_end_frame:\n",
    "                # Only head of the trajectory is in the window\n",
    "                coverage = float(window_end_frame-(start_frame)+1 )/traj_len\n",
    "#                 print coverage\n",
    "            # add trajectory #         add_trajectory call it only when you need it!!!\n",
    "#             trj_obj = Trajectory(int(traj[0]) , float(traj[1]), float(traj[2]), int(traj[3]), int(traj[4]), int(traj[5]), int(traj[6]), coverage)\n",
    "#             new_node.add_trajectory(trj_obj)\n",
    "                    \n",
    "            # Generate the feature data, which will be used to generate 4*4000 histogram\n",
    "            if coverage > traj_coverage_threashold:\n",
    "                features['mean_x'].append(float(traj[1]))\n",
    "                features['mean_y'].append(float(traj[2]))\n",
    "                features['traj'].append(int(traj[3]))\n",
    "                features['hog'].append(int(traj[4]))\n",
    "                features['hof'].append(int(traj[5]))\n",
    "                features['mbh'].append(int(traj[6]))\n",
    "            traj_start_idx +=1\n",
    "#         new_node.record_feature() # obsolete function\n",
    "\n",
    "        # add temporal label to the list:\n",
    "        window_start_time = window_start_frame/fps\n",
    "        window_end_time = window_end_frame/fps\n",
    "        for tlabel_info in video_tLabelList: \n",
    "            over_lap_score = computeOverlap(window_start_time, window_end_time, tlabel_info[1][0], tlabel_info[1][1])\n",
    "            if over_lap_score > 0:\n",
    "                new_node.add_label(tlabel_info, over_lap_score)\n",
    "        # compute and add histogram\n",
    "        new_node.add_feature(features['mean_x'],features['mean_y'],features['traj'],features['hog'],features['hof'],features['mbh'])\n",
    "        # Add this node into a list. \n",
    "        node_list.append(new_node) \n",
    "    # return the list of nodes\n",
    "    for i,node in enumerate(node_list):\n",
    "        node.set_id(i)\n",
    "    return node_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import time\n",
    "# import math\n",
    "# import heapq as pq\n",
    "# from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.13775014877\n"
     ]
    }
   ],
   "source": [
    "NODE_EDGE_DIR = BASE_DIR + \"validation_node_edge/\"\n",
    "cPFile = open(NODE_EDGE_DIR+\"validation_video_nodes.p\", 'rb')\n",
    "t = time.time()\n",
    "node_list = cPickle.load(cPFile)\n",
    "print time.time() - t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.160370826721\n"
     ]
    }
   ],
   "source": [
    "tFile = open(NODE_EDGE_DIR+\"adj_list_by_temporal.p\", 'rb')\n",
    "t = time.time()\n",
    "t_adj_list = cPickle.load(tFile)\n",
    "print time.time() - t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.258911132812\n"
     ]
    }
   ],
   "source": [
    "fFile = open(NODE_EDGE_DIR+\"adj_list_by_feature_k_7_sigma_2000.p\", 'rb')\n",
    "t = time.time()\n",
    "f_adj_list = cPickle.load(fFile)\n",
    "print time.time() - t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished loading the nodes in 4.27256393433 seconds, temporal adjacent list 0.169546127319 seconds, feature adjacent list 0.295833110809 secondes\n",
    "\n",
    "Next step sort the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # labels_id = [[node.labels,node.id] for node in node_list if len(node.labels)>0]\n",
    "\n",
    "    # pprint(labels_id)\n",
    "\n",
    "    # print [node.id for node in node_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,node in enumerate(node_list):\n",
    "        node.set_id(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!!The node id in the generated nodes are not right ?! why?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_id = []\n",
    "for node in node_list:\n",
    "    if len(node.labels) == 1:\n",
    "        labels_id.append([node.labels[0],node.id])\n",
    "    elif len(node.labels) > 1:\n",
    "        for label in node.labels:\n",
    "            labels_id.append([label,node.id])\n",
    "    else:\n",
    "        labels_id.append(['_back_ground',node.id])\n",
    "labels_id = sorted(labels_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pprint((labels_id))\n",
    "    pprint(len(node_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    f_adj_list[12202]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate the matrix which will be plotted, before that we first need to generate a dictionary mapping the node id to their idx in the matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_dict = dict()\n",
    "i = 0\n",
    "for node in labels_id:\n",
    "    if node[1] not in idx_dict:\n",
    "        idx_dict[node[1]] = []\n",
    "    idx_dict[node[1]].append(i)\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    f_adj_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_mat = np.zeros([len(labels_id),len(labels_id)])\n",
    "i = 0\n",
    "for node in labels_id:\n",
    "    adlist = f_adj_list[node[1]]\n",
    "    for edge in adlist:\n",
    "        idx = idx_dict[edge[1]]\n",
    "        f_mat[i][idx] = 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_mat = np.zeros([len(labels_id),len(labels_id)])\n",
    "i = 0\n",
    "for node in labels_id:\n",
    "    adlist = t_adj_list[node[1]]\n",
    "    for edge in adlist:\n",
    "        idx = idx_dict[edge[1]]\n",
    "        t_mat[i][idx] = 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.matshow(f_mat)\n",
    "# Display a random matrix with a specified figure number and a grayscale\n",
    "# colormap\n",
    "# plt.matshow(np.random.rand(64, 64), fignum=100, cmap=plt.cm.gray)\n",
    "# plt.savefig('matrix.bmp')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.matshow(f_mat,cmap='Greys')\n",
    "plt.savefig('f_matrix3000.png', dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.matshow(t_mat,cmap='Greys')\n",
    "plt.savefig('t_matrix2000.png', dpi=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('t_matrix2500.png', dpi=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.savefig('matrix.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.savefig('matrix.bmp', dpi=1000)\n",
    "# Not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('matrix2000.png', dpi=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('t_matrix3000.png', dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('matrix4000.png', dpi=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sio.savemat('matrix.mat', {'f_matrix':f_mat,'t_matrix':t_mat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump( {'f_matrix':f_mat,'t_matrix':t_mat}, open( NODE_EDGE_DIR +\"mats.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_nodes = []\n",
    "for node in node_list:\n",
    "    if len(node.labels) == 1:\n",
    "        labeled_nodes.append([node.labels[0],node.id])\n",
    "    elif len(node.labels) > 1:\n",
    "        for label in node.labels:\n",
    "            labeled_nodes.append([label,node.id])\n",
    "len(labeled_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.matshow(f_mat[:1662,:1662],cmap='Greys')\n",
    "plt.savefig('f_matrix_positive3000.png', dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.matshow(t_mat[:1662,:1662],cmap='Greys')\n",
    "plt.savefig('t_matrix_positive3000.png', dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idx_dict_positive = dict()\n",
    "# i = 0\n",
    "# for node in labeled_nodes:\n",
    "#     if node[1] not in idx_dict_positive:\n",
    "#         idx_dict_positive[node[1]] = []\n",
    "#     idx_dict_positive[node[1]].append(i)\n",
    "#     i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f_mat_labeled = np.zeros([len(labeled_nodes),len(labeled_nodes)])\n",
    "# i = 0\n",
    "# for node in labeled_nodes:\n",
    "#     adlist = f_adj_list[node[1]]\n",
    "#     for edge in adlist:\n",
    "#         if edge[1] in idx_dict_positive:\n",
    "#             idx = idx_dict_positive[edge[1]]\n",
    "#         if idx < len(labeled_nodes):\n",
    "#             f_mat_labeled[i][idx] = 1\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t_mat_labeled = np.zeros([len(labeled_nodes),len(labeled_nodes)])\n",
    "# i = 0\n",
    "# for node in labeled_nodes:\n",
    "#     adlist = t_adj_list[node[1]]\n",
    "#     for edge in adlist:\n",
    "#         if edge[1] in idx_dict_positive:\n",
    "#             idx = idx_dict_positive[edge[1]]\n",
    "#         if idx < len(labeled_nodes):\n",
    "#             t_mat_labeled[i][idx] = 1\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# plt.matshow(f_mat_labeled,cmap='Greys')\n",
    "# plt.savefig('f_matrix_positive3000.png', dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# plt.matshow(t_mat_labeled,cmap='Greys')\n",
    "# plt.savefig('t_matrix_positive3000.png', dpi=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
