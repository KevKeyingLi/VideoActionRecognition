{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "* graph generator:\n",
    "    * a graph generator: that generates graphs according to the temporal adjacency(later use other features)\n",
    "    * nodes are short video clips in each sliding window\n",
    "    * Edges are defined as the distance of two windows.\n",
    "    * Weight of edges should be between 0 and 1\n",
    "    * The parameters should be tweakable: window length, step size, ...\n",
    "    * each node have the information of start time, end time, and feature vector.\n",
    "    * The result should be an adjacent list of nodes. also having the weight infomation. \n",
    "    * make the graph symetric\n",
    "    \n",
    "* Questions:\n",
    "    - What would be a good way of representing the nodes.\n",
    "        + Objects: learn python\n",
    "        \n",
    "# Steps\n",
    "## Make the nodes:\n",
    "short videos, feature are the histogram of 4*4000 dimensional features. \n",
    "\n",
    "## Make the edges:\n",
    "the edges are similarities of nodes, use overlaping for time window, use the following function for feature:\n",
    "$$e^{\\frac{1}{\\sigma^2}||x_1-x_2||_2^2}$$\n",
    "include only the top K edges for each node, where K is a parameter\n",
    "make it symmetric graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats from UFC 101 dataset\n",
    "| |frames|seconds|\n",
    "|---|---|--|\n",
    "|max length|1776|   71.04 |\n",
    "|min length|29| 1.06666666667 |\n",
    "|mean|186.528562849|   7.2053465966 |\n",
    "|median|167|  6.48 |\n",
    "|std|97.7848059441 |  3.75795650803 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from scipy import io as sio\n",
    "import time\n",
    "BASE_DIR = '/Users/baroc/repos/VideoActionRecognition/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, start, end, fps, videoname):\n",
    "        self.id = 0;\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.fps = fps\n",
    "        self.videoname = videoname \n",
    "        self.trajectories = []\n",
    "#         self.features = dict()\n",
    "#         # contains six lists of what features are avaible. This info can be used to compute the histogram\n",
    "#         # use numpy.histogram or scipy.stat.histogram\n",
    "#         self.features['mean_x'] = []\n",
    "#         self.features['mean_y'] = []\n",
    "#         self.features['traj_idx'] = []\n",
    "#         self.features['hog'] = []\n",
    "#         self.features['hof'] = []\n",
    "#         self.features['mbh'] = []\n",
    "        self.histogram = []\n",
    "        self.allOverLapLabels = dict() # a dictionary of {overlapping label: [lb_str_t, lb_end_t], overlap}\n",
    "        self.labels = [] # only the labels that are considered positive.\n",
    "        # add groud truth\n",
    "        \n",
    "    def add_trajectory(self, traj): # call this when you need it\n",
    "        self.trajectories.append(traj)\n",
    "    def add_label(self, tlabel_info, overlap): # \n",
    "        # add to allOverLapLabels\n",
    "        # tlabel_info = ['video_validation_0000051', [67.5, 75.9], 'Billiards']\n",
    "        if tlabel_info[2] in self.allOverLapLabels:\n",
    "            self.allOverLapLabels[tlabel_info[2]].append([tlabel_info[1],overlap])\n",
    "        else:\n",
    "            self.allOverLapLabels[tlabel_info[2]] = [[tlabel_info[1],overlap]]\n",
    "#             self.allOverLapLabels[tlabel_info[2]].append([tlabel_info[1],overlap])\n",
    "        # add to labels\n",
    "        if overlap>0.5:\n",
    "            self.labels.append(tlabel_info[2]) # it is possible that there are multiple same label for a node.\n",
    "    def record_feature(self): \n",
    "        ###########\n",
    "        # this method currently counts all existence, and don't take into account the coverage of each trajectory\n",
    "        # if need the coverage info in the future, can simply modify to:\n",
    "        # self.feature_cnt['mean_x'].append([traj.mean_x,traj.coverage])\n",
    "        \n",
    "        if len(self.features['traj_idx']) == 0:\n",
    "            raise ValueError(\"record_features not usable. Because no features. Use add_feature in loop instead. \")\n",
    "        for traj in self.trajectories:\n",
    "            self.features['mean_x'].append(traj.mean_x)\n",
    "            self.features['mean_y'].append(traj.mean_y)\n",
    "            self.features['traj_idx'].append(traj.traj_idx)\n",
    "            self.features['hog'].append(traj.hog)\n",
    "            self.features['hof'].append(traj.hof)\n",
    "            self.features['mbh'].append(traj.mbh)\n",
    "        return\n",
    "    \n",
    "    def add_feature(self, mean_x, mean_y, traj, hog, hof, mbh):\n",
    "        # this function computes and adds the histogram of the 16,000 features, \n",
    "        # and adds the mean_x mean_y information if necessary\n",
    "        hist_hog = np.histogram(hog,4000,(0,4000))[0]\n",
    "        hist_hof = np.histogram(hof,4000,(0,4000))[0]\n",
    "        hist_mbh = np.histogram(mbh,4000,(0,4000))[0]\n",
    "        hist_traj = np.histogram(traj,4000,(0,4000))[0]\n",
    "        self.histogram = np.concatenate((hist_traj, hist_hog, hist_hof, hist_mbh))\n",
    "#         self.mean_x = mean_x\n",
    "#         self.mean_y = mean_y\n",
    "    def set_id(self, idx):\n",
    "        self.id = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next: implement the method add_feature\n",
    "and modify the related code, and add histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trajectory:\n",
    "    def __init__(self, frame_num, mean_x, mean_y, traj_idx, hog, hof, mbh, coverage):\n",
    "        self.frame_num  = frame_num \n",
    "        self.mean_x  = mean_x \n",
    "        self.mean_y  = mean_y \n",
    "        self.traj_idx  = traj_idx \n",
    "        self.hog  = hog\n",
    "        self.hof  = hof\n",
    "        self.mbh  = mbh\n",
    "        self.coverage = coverage # The portion of trajectory included in the window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeOverlap(window_start, window_end, label_start, label_end):\n",
    "    \n",
    "    if window_start < label_end and label_start < window_end:\n",
    "        # overlap\n",
    "        if window_start > label_start:\n",
    "            l_start = window_start\n",
    "            s_start = label_start\n",
    "        else:\n",
    "            l_start = label_start\n",
    "            s_start = window_start \n",
    "        if window_end > label_end:\n",
    "            l_end = window_end\n",
    "            s_end = label_end\n",
    "        else:\n",
    "            l_end = label_end\n",
    "            s_end = window_end \n",
    "        return (s_end-l_start)/(l_end - s_start)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateNode(video_info, video_tLabelList, windowSize = 150, stepSize = 100):# by frame, default value comes from the Thumos report.\n",
    "    # generate nodes for a video, return a list of Node\n",
    "    # before calling this function, require to find the video_info and video_tLabelList for this video. \n",
    "    video_name = video_info[0][0]\n",
    "    duration_frame = video_info[8][0][0]\n",
    "    fps = float(video_info[9][0])\n",
    "    # read in the file and form a list of trajectory features\n",
    "    with open(BASE_DIR + 'TH14_validation_features/'+video_name+'.txt','r') as f:\n",
    "        # later: make the directory as a variable\n",
    "        trajs = f.readlines()\n",
    "    trajs = [x.split('\\t')[:-1] for x in trajs]\n",
    "    ####################for debug\n",
    "#     trajs = trajs[:308001]\n",
    "    #####################\n",
    "    traj_start_idx = 0 # the index of the first trajectory of each window\n",
    "    next_traj_idx = 0\n",
    "    next_traj_set = False\n",
    "    # form a list of window start point. \n",
    "    frame_step_list = range(1, duration_frame, stepSize)# The start of frame? \n",
    "    # Do you also need to consider the window to be full length, not truncated on the last few steps. \n",
    "    # Note that in the dataset, there is no trajectory ending on the last frame, so we don't use duration_frame+1\n",
    "    window_start = 0\n",
    "    window_end = 0\n",
    "    node_list = []\n",
    "    \n",
    "    for i in range(len(frame_step_list) ):# For each window\n",
    "        if(frame_step_list[i] + windowSize < duration_frame):\n",
    "            # Both start and end are inclusive\n",
    "            window_start = frame_step_list[i]\n",
    "            window_end = frame_step_list[i] + windowSize - 1\n",
    "        elif frame_step_list[i] + windowSize < duration_frame+stepSize:\n",
    "            # The last window\n",
    "            window_start = frame_step_list[i]\n",
    "            window_end = duration_frame\n",
    "        else:\n",
    "            # Extra windows\n",
    "            break\n",
    "#         print window_start,window_end\n",
    "        \n",
    "        traj_start_idx = next_traj_idx \n",
    "        # next_traj_idx is used to record the start trajectory of next window, when constructing the current node\n",
    "        next_traj_set = False\n",
    "        # initialize node\n",
    "        traj = trajs[traj_start_idx] # Current trajectory\n",
    "        end_frame = int(traj[0])\n",
    "        start_frame = end_frame-15+1\n",
    "        new_node = Node(window_start, window_end, fps, video_name)\n",
    "        \n",
    "        # feature list\n",
    "        features = dict()\n",
    "        features['mean_x'] = []\n",
    "        features['mean_y'] = []\n",
    "        features['traj'] = []\n",
    "        features['hog'] = []\n",
    "        features['hof'] = []\n",
    "        features['mbh'] = []\n",
    "        # Add trajectories, \n",
    "        while(traj_start_idx<len(trajs) and (window_start<=end_frame<=window_end or window_start<=start_frame<=window_end)):\n",
    "            coverage = 1.0\n",
    "            traj = trajs[traj_start_idx] # Current trajectory\n",
    "            end_frame = int(traj[0])\n",
    "            start_frame = end_frame-15+1\n",
    "#             print \"start and end\"+ str(start_frame)+' , '+str(end_frame)\n",
    "            if not next_traj_set and i+1 < len(frame_step_list) and end_frame >= frame_step_list[i+1]:\n",
    "                next_traj_idx = traj_start_idx\n",
    "                next_traj_set = True\n",
    "            if(end_frame<= window_end and window_start<=start_frame):\n",
    "                pass\n",
    "            # this trajectory is totally in the window\n",
    "            #     coverage = 1.0\n",
    "            elif start_frame < window_start and window_start <= end_frame: # first few trajs\n",
    "                # Only the tail of the trajectory is in the window\n",
    "                coverage = float(end_frame - window_start + 1)/15\n",
    "#                 print coverage\n",
    "            elif window_end >= start_frame and end_frame>window_end:\n",
    "                # Only head of the trajectory is in the window\n",
    "                coverage = float(window_end-(start_frame)+1 )/15\n",
    "#                 print coverage\n",
    "            # add trajectory #         add_trajectory call it only when you need it!!!\n",
    "#             trj_obj = Trajectory(int(traj[0]) , float(traj[1]), float(traj[2]), int(traj[3]), int(traj[4]), int(traj[5]), int(traj[6]), coverage)\n",
    "#             new_node.add_trajectory(trj_obj)\n",
    "                    \n",
    "            # Generate the feature data, which will be used to generate 4*4000 histogram\n",
    "            features['mean_x'].append(float(traj[1]))\n",
    "            features['mean_y'].append(float(traj[2]))\n",
    "            features['traj'].append(int(traj[3]))\n",
    "            features['hog'].append(int(traj[4]))\n",
    "            features['hof'].append(int(traj[5]))\n",
    "            features['mbh'].append(int(traj[6]))\n",
    "            traj_start_idx +=1\n",
    "#         new_node.record_feature() # obsolete function\n",
    "\n",
    "        # add temporal label to the list:\n",
    "        window_start_time = window_start * fps\n",
    "        window_end_time = window_end * fps\n",
    "        for tlabel_info in video_tLabelList: \n",
    "            over_lap_score = computeOverlap(window_start_time, window_end_time, tlabel_info[1][0], tlabel_info[1][1])\n",
    "            if over_lap_score > 0:\n",
    "                new_node.add_label(tlabel_info, over_lap_score)\n",
    "        # compute and add histogram\n",
    "        new_node.add_feature(features['mean_x'],features['mean_y'],features['traj'],features['hog'],features['hof'],features['mbh'])\n",
    "        # Add this node into a list. \n",
    "        node_list.append(new_node) \n",
    "    # return the list of nodes\n",
    "    for i,node in enumerate(node_list):\n",
    "        node.set_id(i)\n",
    "    return node_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: loading and accessing one of the feature file, uncomment to see results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_feature_file = '/Users/baroc/repos/VideoDetection/TH14_validation_features/video_validation_0000001.txt'\n",
    "# with open(test_feature_file,'r') as f:\n",
    "#     trajs = f.readlines()\n",
    "# trajs = [x.split('\\t')[:-1] for x in trajs]\n",
    "# pprint(trajs[:5])\n",
    "# # for x in lines:\n",
    "# #     if(len(x)!=7 ):\n",
    "# #         print x\n",
    "# # Every line is good. \n",
    "# # [ end_frame, mean_x, mean_y, traj_id, hog, hof, mbh ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the labels\n",
    "This following snippet reads and sorts the temporal labels for videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['video_validation_0000051', [67.5, 75.9], 'Billiards'],\n",
      " ['video_validation_0000051', [85.9, 90.6], 'Billiards'],\n",
      " ['video_validation_0000051', [139.3, 148.2], 'Billiards'],\n",
      " ['video_validation_0000052', [24.3, 24.8], 'Billiards'],\n",
      " ['video_validation_0000053', [9.1, 13.8], 'Billiards']]\n",
      "[['video_validation_0000162', [152.5, 155.1], 'Diving'],\n",
      " ['video_validation_0000162', [155.8, 158.5], 'CliffDiving'],\n",
      " ['video_validation_0000162', [155.8, 158.5], 'Diving'],\n",
      " ['video_validation_0000162', [163.0, 164.0], 'Ambiguous'],\n",
      " ['video_validation_0000162', [164.1, 167.1], 'CliffDiving']]\n",
      "['video_validation_0000051',\n",
      " 'video_validation_0000052',\n",
      " 'video_validation_0000053',\n",
      " 'video_validation_0000054',\n",
      " 'video_validation_0000055',\n",
      " 'video_validation_0000056',\n",
      " 'video_validation_0000057',\n",
      " 'video_validation_0000058',\n",
      " 'video_validation_0000059',\n",
      " 'video_validation_0000060']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "TLBL_DIR = BASE_DIR + 'TH14_Temporal_annotations_validation/annotation/' #'./''\n",
    "filelist = os.listdir(TLBL_DIR)\n",
    "tLabelList = []\n",
    "for filename in filelist:\n",
    "    if filename.endswith(\"_val.txt\"): \n",
    "        with open(TLBL_DIR+filename,'r') as f:\n",
    "            tLabels = f.readlines()\n",
    "        tLabels = [x[:-1].split('  ') for x in tLabels]\n",
    "        tLabels = [[x[0],map(float, x[1].split(' '))] for x in tLabels]\n",
    "        tLabels = [x+[filename[:-8]] for x in tLabels]\n",
    "        tLabelList = tLabelList+tLabels\n",
    "    else:\n",
    "        print('Not a txt file: '+filename)\n",
    "tLabelList = sorted(tLabelList)\n",
    "videonames = sorted(list(set([x[0] for x in tLabelList])))\n",
    "pprint(tLabelList[:5])\n",
    "pprint(tLabelList[170:175])\n",
    "# print '\\n'\n",
    "pprint(videonames[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the temporal action detection task, we only care about the 200 videos with temporal label. The next snippet extracts the meta data of these videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_file_str=BASE_DIR+\"validation_set_meta/validation_set_meta/validation_set.mat\"\n",
    "mat = sio.loadmat(mat_file_str)\n",
    "meta_array_1010 = mat['validation_videos'][0] # 1010 entries in meta_array\n",
    "id_list = [int(x[-7:])-1 for x in videonames] # a list of zero based indices\n",
    "meta_array_200 = meta_array_1010[id_list]\n",
    "len(meta_array_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are two ways to get meta data, meta_1010 is better for access by index,  meta_200 is better for looping through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Node generation\n",
    "The following few lines of code **tests** the generate node function:\n",
    "* First, load the meta data of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([u'video_validation_0000161'], [u'ACAPULCO MEXICO  - CLIFF DIVERS OF LA QUEBRADA.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6')]], [[26]], [u'NO'], [[61.83]], [[1852]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000162'], [u'Celebrating 5 Years of the Red Bull Cliff Diving World Series.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6')]], [[26]], [u'NO'], [[198.136]], [[5941]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000163'], [u'Cliff Diving in Norway - Red Bull Cliff Diving World Series 2012 Grimstad.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6'), array([u'Rowing'], \n",
      "      dtype='<U6'), array([u'Surfing'], \n",
      "      dtype='<U7')]], [[26], [76], [88]], [u'NO'], [[233.976]], [[7016]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000164'], [u'Cliff diving qualification - Red Bull Cliff Diving World Series 2012.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6')]], [[26]], [u'NO'], [[173.477]], [[5201]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000165'], [u'Counting Down to La Rochelle - Red Bull Cliff Diving World Series 2011.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6')]], [[26]], [u'NO'], [[106.473]], [[3191]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000166'], [u'Rapa Nui event highlights - Red Bull Cliff Diving World Series 2011.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6')]], [[26]], [u'NO'], [[145.395]], [[4359]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000167'], [u'South Point Cliff Diving.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6')]], [[26]], [u'NO'], [[210.936]], [[6325]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000168'], [u'Top 15 Most Extreme Cliff Jumps - Cliff Jumping  Diving.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6')]], [[26]], [u'NO'], [[136.958]], [[4106]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000169'], [u'Waimea cliff jump.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6')]], [[26]], [u'NO'], [[194.27]], [[5825]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000170'], [u'Wearing the label Cliff Diver with pride - Red Bull Cliff Diving World Series 2012.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
      "      dtype='<U6')]], [[26]], [u'NO'], [[215.978]], [[6476]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000176'], [u'Cricket bowling at its best  bowled ! bowled! bowled!.mpeg'], [u'CricketBowling'], [[23]], [[array([u'CricketShot'], \n",
      "      dtype='<U11')]], [[24]], [u'NO'], [[137.428]], [[4120]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000179'], [u'Matthew Wade Bowling and Phil Hughes Wicket Keeping in Test cricket.mpeg'], [u'CricketBowling'], [[23]], [[array([u'CricketShot'], \n",
      "      dtype='<U11')]], [[24]], [u'NO'], [[185.754]], [[5570]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000180'], [u'SHOAIB AKHTAR WORLDs FASTEST BOWLER.mpeg'], [u'CricketBowling'], [[23]], [[array([u'CricketShot'], \n",
      "      dtype='<U11')]], [[24]], [u'NO'], [[220.706]], [[6618]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000181'], [u'Best helicopter Shot By Omkar Desai in Tennis Cricket Mumbai.mpeg'], [u'CricketShot'], [[24]], [[array([u'CricketBowling'], \n",
      "      dtype='<U14')]], [[23]], [u'NO'], [[148.974]], [[4466]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000184'], [u'Dhoni Sensational Helicopter Shots.mpeg'], [u'CricketShot'], [[24]], [[array([u'CricketBowling'], \n",
      "      dtype='<U14')]], [[23]], [u'NO'], [[168.54]], [[5053]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000187'], [u'Sachin Tendulkar -Funny Cricket Shot-amazing.mpeg'], [u'CricketShot'], [[24]], [[array([u'CricketBowling'], \n",
      "      dtype='<U14')]], [[23]], [u'NO'], [[60.027]], [[1798]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000188'], [u'Sachin vs Ganguly vs Dravid vs MS Dhoni 4 BEST Shots Ever !! Must WATCH !!.mpeg'], [u'CricketShot'], [[24]], [[array([u'CricketBowling'], \n",
      "      dtype='<U14')]], [[23]], [u'NO'], [[170.499]], [[5112]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000189'], [u'The weirdest cricket shot in history massive WTF!!!!.mpeg'], [u'CricketShot'], [[24]], [[array([u'CricketBowling'], \n",
      "      dtype='<U14')]], [[23]], [u'NO'], [[110.966]], [[3326]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000190'], [u'best cricket shot.mpeg'], [u'CricketShot'], [[24]], [[array([u'CricketBowling'], \n",
      "      dtype='<U14')]], [[23]], [u'NO'], [[8.932]], [[265]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000206'], [u'Diving board tricks.mpeg'], [u'Diving'], [[26]], [[array([u'TrampolineJumping'], \n",
      "      dtype='<U17')]], [[94]], [u'NO'], [[179.172]], [[5372]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000264'], [u'Epic Trick Shot Battle  Dude Perfect vs Brodie.mpeg'], [u'FrisbeeCatch'], [[31]], [[array([u'Basketball'], \n",
      "      dtype='<U10'), array([u'TrampolineJumping'], \n",
      "      dtype='<U17')]], [[8], [94]], [u'NO'], [[283.766]], [[8510]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000266'], [u'Greatest Sports Catches of All Time 247 Trickshots_x264.mpeg'], [u'FrisbeeCatch'], [[31]], [[array([u'BaseballPitch'], \n",
      "      dtype='<U13'), array([u'TrampolineJumping'], \n",
      "      dtype='<U17')]], [[7], [94]], [u'NO'], [[171.57]], [[5144]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000268'], [u'Top 21 Frisbee Trick Shots 2012  Brodie Smith.mpeg'], [u'FrisbeeCatch'], [[31]], [[array([u'TrampolineJumping'], \n",
      "      dtype='<U17')]], [[94]], [u'NO'], [[306.362]], [[9188]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000316'], [u'Essential Hammer Throw Special Strength Exercises.mpeg'], [u'HammerThrow'], [[36]], [[array([u'ThrowDiscus'], \n",
      "      dtype='<U11')]], [[93]], [u'NO'], [[201.794]], [[6051]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000414'], [u'Biomechanics and Measurement of Javelin Throwing.mpeg'], [u'JavelinThrow'], [[45]], [[array([u'WritingOnBoard'], \n",
      "      dtype='<U14')]], [[100]], [u'NO'], [[302.887]], [[9084]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000663'], [u'Eirik Greibrokk Dolve Pole Vault.mpeg'], [u'PoleVault'], [[68]], [[array([u'TrampolineJumping'], \n",
      "      dtype='<U17')]], [[94]], [u'NO'], [[226.061]], [[6779]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000901'], [u'2014 Sprite Slam Dunk - East Freestyle Dunk Mix.mpeg'], [u'BasketballDunk'], [[9]], [[array([u'Basketball'], \n",
      "      dtype='<U10')]], [[8]], [u'NO'], [[121.441]], [[3640]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000902'], [u'All Dunks Of 2014  All Star Saturday Night Sprite Slam Dunk Contest.mpeg'], [u'BasketballDunk'], [[9]], [[array([u'Drumming'], \n",
      "      dtype='<U8')]], [[27]], [u'NO'], [[593.291]], [[17778]], [[29.97002997002997]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000903'], [u'All Dunks Of 2014 Boost Mobile NBA D-League Slam Dunk Contest.mpeg'], [u'BasketballDunk'], [[9]], [[array([u'Basketball'], \n",
      "      dtype='<U10')]], [[8]], [u'NO'], [[547.681]], [[16411]], [[29.97002997002997]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000904'], [u'Backboard Breaking Dunks [Super Cut Compilation].mpeg'], [u'BasketballDunk'], [[9]], [[array([u'Basketball'], \n",
      "      dtype='<U10')]], [[8]], [u'NO'], [[228.674]], [[6857]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000907'], [u'Paul Pierce Killer Crossover to Slam Dunk.mpeg'], [u'BasketballDunk'], [[9]], [[array([u'Basketball'], \n",
      "      dtype='<U10')]], [[8]], [u'NO'], [[34.767]], [[1040]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000909'], [u'Top 10 Dunks of the 2012-2013 NBA Season.mpeg'], [u'BasketballDunk'], [[9]], [[array([u'Basketball'], \n",
      "      dtype='<U10')]], [[8]], [u'NO'], [[196.987]], [[5907]], [[30]], [[180]], [[320]]),\n",
      " ([u'video_validation_0000910'], [u'Top 10 Dunks of the NBA 2011-2012 Season.mpeg'], [u'BasketballDunk'], [[9]], [[array([u'Basketball'], \n",
      "      dtype='<U10')]], [[8]], [u'NO'], [[192.233]], [[5764]], [[30]], [[180]], [[320]])]\n",
      "video_validation_0000163\n",
      "7016\n",
      "[['video_validation_0000163', [37.2, 41.2], 'CliffDiving'],\n",
      " ['video_validation_0000163', [37.2, 41.2], 'Diving'],\n",
      " ['video_validation_0000163', [53.6, 57.6], 'CliffDiving'],\n",
      " ['video_validation_0000163', [53.6, 57.6], 'Diving'],\n",
      " ['video_validation_0000163', [94.0, 98.1], 'CliffDiving'],\n",
      " ['video_validation_0000163', [94.0, 98.1], 'Diving'],\n",
      " ['video_validation_0000163', [104.6, 107.3], 'CliffDiving'],\n",
      " ['video_validation_0000163', [104.6, 107.3], 'Diving'],\n",
      " ['video_validation_0000163', [127.9, 131.5], 'CliffDiving'],\n",
      " ['video_validation_0000163', [127.9, 131.5], 'Diving'],\n",
      " ['video_validation_0000163', [148.7, 157.0], 'CliffDiving'],\n",
      " ['video_validation_0000163', [148.7, 157.0], 'Diving'],\n",
      " ['video_validation_0000163', [172.8, 177.0], 'CliffDiving'],\n",
      " ['video_validation_0000163', [172.8, 177.0], 'Diving']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([u'video_validation_0000162'], [u'Celebrating 5 Years of the Red Bull Cliff Diving World Series.mpeg'], [u'CliffDiving'], [[22]], [[array([u'Diving'], \n",
       "      dtype='<U6')]], [[26]], [u'NO'], [[198.136]], [[5941]], [[30]], [[180]], [[320]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mat_file_str=\"/Users/baroc/repos/VideoDetection/validation_set_meta/validation_set_meta/validation_set.mat\"\n",
    "# mat = sio.loadmat(mat_file_str)\n",
    "# meta_array = mat['validation_videos'][0] # 1010 entries in meta_array\n",
    "# NUM_VIDEOS = 1010\n",
    "\n",
    "pprint([x for x in meta_array_200 if len(x[4])>0 ]) # These are videos with multiple actions\n",
    "video_info = meta_array_1010[162]\n",
    "print(video_info[0][0])\n",
    "print(video_info[8][0][0])\n",
    "video_tLabelList = [x for x in tLabelList if x[0]==video_info[0][0]]\n",
    "pprint(video_tLabelList)\n",
    "meta_array_1010[161]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Invoke the `generateNode` function and time it. 150.58s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapse 13.27\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "node_list = generateNode(video_info, video_tLabelList)#, 100, 50)\n",
    "print('time elapse %.2f'% (time.time()-t) )# 19.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.85 for original node implementation of feature data\n",
    "13.27 for new histogram implementation + light members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test if the result is right for original implemenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # node_list[0].start\n",
    "# # node_list[0].end\n",
    "\n",
    "# trajs = node_list[2].trajectories\n",
    "# print('All in all '+str(len(trajs))+' trajectories' )\n",
    "# # [x.coverage for x in trajs[5000:5010]]\n",
    "# print \"end \"+str(trajs[-1].frame_num) # problem\n",
    "# print trajs[5000].frame_num\n",
    "# print trajs[0].frame_num\n",
    "# print trajs[-1].coverage\n",
    "# print '\\n'\n",
    "# print len(node_list[2].features['hof'])\n",
    "# print len(node_list[2].features['hog'])\n",
    "# print len(node_list[2].features['mean_x'])\n",
    "# print len(node_list[2].features['mean_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  2,  0,  0,  0,  1,  7,  4,  1, 18,  0,  4,  8,  1,  1,  1,\n",
       "        0,  0,  4,  0,  0,  0,  1,  0,  7,  0,  7,  4,  1, 11,  2,  6,  2,\n",
       "        2, 32,  0,  3, 10,  2,  4,  0,  2,  0,  8, 25,  1,  4,  0,  2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = node_list[2].histogram\n",
    "# print('All in all '+str(len(hist))+' histogram dimensions' )\n",
    "# [x.coverage for x in trajs[5000:5010]]\n",
    "print len(hist)\n",
    "hist[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The result is right\n",
    "\n",
    "Till now, we are able to generate nodes from feature files.\n",
    "\n",
    "Next step would be save the node information into a file.\n",
    "\n",
    "So later we can use it to generate edge/graph\n",
    "\n",
    "But before that, I have a few questions on saving the data. \n",
    "* Of course, I can simply pickle it, but considering the matlab compatibility, might be better to use .mat\n",
    "* How to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [[x.coverage,x.frame_num] for x in trajs[6589:]]\n",
    "# len(trajs[6589:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "b = 3\n",
    "float(a)/b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with pickle\n",
    "Skip this part, since this is only experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_validation_0000163\n",
      "26.4432079792\n",
      "106.701439142\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cPickle\n",
    "print(video_info[0][0])\n",
    "t = time.time()\n",
    "cPickle.dump( node_list, open( BASE_DIR + video_info[0][0]+\".cp\", \"wb\" ) )\n",
    "print(time.time()-t)\n",
    "t = time.time()\n",
    "pickle.dump( node_list, open( BASE_DIR + video_info[0][0]+\".p\", \"wb\" ) )\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result show that when pickling one video \" \", cPickle takes 26.4432079792s to save to a 251.4MB file, pickle takes 106.701439142 to save to a 224.5MB file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.192363024\n",
      "131.941593885\n"
     ]
    }
   ],
   "source": [
    "cPFile = open(BASE_DIR\"+video_info[0][0]+\".cp\", 'rb')\n",
    "t = time.time()\n",
    "cP = cPickle.load(cPFile)\n",
    "print(time.time()-t)\n",
    "cPFile.close()\n",
    "PFile = open(\"/Users/baroc/repos/VideoDetection/\"+video_info[0][0]+\".p\", 'rb')\n",
    "t = time.time()\n",
    "P = cPickle.load(PFile)\n",
    "print(time.time()-t)\n",
    "PFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle load .cp 118.874449968 .p 129.021311998\n",
    "cpickle load .cp 114.192363024 .p 131.941593885"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I would like to try highest protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.3370029926\n",
      "189.640047789\n"
     ]
    }
   ],
   "source": [
    "# protocol=pickle.HIGHEST_PROTOCOL\n",
    "t = time.time()\n",
    "cPickle.dump( node_list, open( \"/Users/baroc/repos/VideoDetection/\"+video_info[0][0]+\".cp\", \"wb\" ), protocol=pickle.HIGHEST_PROTOCOL )\n",
    "print(time.time()-t)\n",
    "t = time.time()\n",
    "pickle.dump( node_list, open( \"/Users/baroc/repos/VideoDetection/\"+video_info[0][0]+\".p\", \"wb\" ), protocol=pickle.HIGHEST_PROTOCOL )\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with highest protocal, cpickle take 68.3370029926s to save the video to a 122.5MB file, pickle take 189.640047789s to save to a 122.5MB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.124447107\n",
      "129.871397972\n"
     ]
    }
   ],
   "source": [
    "cPFile = open(\"/Users/baroc/repos/VideoDetection/\"+video_info[0][0]+\".cp\", 'rb')\n",
    "t = time.time()\n",
    "cP = cPickle.load(cPFile)\n",
    "print(time.time()-t)\n",
    "cPFile.close()\n",
    "PFile = open(\"/Users/baroc/repos/VideoDetection/\"+video_info[0][0]+\".p\", 'rb')\n",
    "t = time.time()\n",
    "P = cPickle.load(PFile)\n",
    "print(time.time()-t)\n",
    "PFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading cP: 124.124447107 .p: 129.871397972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17989"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(P[2].trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "import cPickle\n",
    "t = time.time()\n",
    "cPickle.dump( node_list, open( BASE_DIR+video_info[0][0]+\".p\", \"wb\" ), protocol=cPickle.HIGHEST_PROTOCOL )\n",
    "print(time.time()-t) # 14.753661871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0107200145721\n"
     ]
    }
   ],
   "source": [
    "cPFile = open(BASE_DIR+video_info[0][0]+\".p\", 'rb')\n",
    "t = time.time()\n",
    "cP = cPickle.load(cPFile)\n",
    "print(time.time()-t)\n",
    "cPFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.753661871 to save, 131.248260021 to load for original heavy implementation, about 122 mb\n",
    "\n",
    "0.0320661067963 to save, 0.0107200145721 to load for new light implementation, only 9 mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the histogram of a node\n",
    "#### Test histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 20  3 14  9  2  9 17 12  6 26  0 13 15  1  0  3  2  8  0]\n",
      "[ 6 20  3 14  9  2  9 17 12  6 26  0 13 15  1  0  3  2  8  0]\n"
     ]
    }
   ],
   "source": [
    "hist_list = []\n",
    "hist_hog = np.histogram(node_list[0].features['hog'],4000,(0,4000))[0]\n",
    "hist_hof = np.histogram(node_list[0].features['hof'],4000,(0,4000))[0]\n",
    "hist_mbh = np.histogram(node_list[0].features['mbh'],4000,(0,4000))[0]\n",
    "hist_traj = np.histogram(node_list[0].features['traj_idx'],4000,(0,4000))[0]\n",
    "# node_list[0].features['hog'] #2955, 3883, 2955, 2332, 2311, 2216,\n",
    "# hist_feature = np.append(hist_hog, hist_hof)\n",
    "# hist_feature = np.append(hist_feature, hist_mbh)\n",
    "# hist_feature = np.append(hist_feature, hist_traj)\n",
    "hist_feature = np.concatenate((hist_traj, hist_hog, hist_hof, hist_mbh))\n",
    "len(hist_feature)\n",
    "# type(hist_hog)\n",
    "print(hist_feature[0:20])\n",
    "print(hist_traj[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  1  8  3  3  0  0  0  0  0 17  0  4 16  0  0  0  0  0 14]\n",
      "[ 2  1  8  3  3  0  0  0  0  0 17  0  4 16  0  0  0  0  0 14]\n"
     ]
    }
   ],
   "source": [
    "print(hist_feature[4000:4020])\n",
    "print(hist_hog[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final histogram\n",
    "is in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OMG, I should have just computed the histogram, fkr**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After finishing all the functions this will be the start point? Maybe\n",
    "The program start point: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USR_WIN = 150\n",
    "USR_STEP = 100\n",
    "mat_file_str=\"/Users/baroc/repos/VideoDetection/validation_set_meta/validation_set_meta/validation_set.mat\"\n",
    "mat = sio.loadmat(mat_file_str)\n",
    "meta_array = mat['validation_videos'][0]\n",
    "NUM_VIDEOS = 1010\n",
    "for i in range(NUM_VIDEOS):\n",
    "    video_info = meta_array[i]\n",
    "# a structure of ([u'video_validation_0000102'], [u'Boxing Tips  - How to Punch a Boxing Bag.mpeg'], [u'BoxingPunchingBag'], [[17]], \n",
    "#    [[array([u'Punch'], dtype='<U5')]], [[71]], [u'NO'], [[152.84]], [[4582]], [[30]], [[180]], [[320]])\n",
    "    video_name = video_info[0][0]\n",
    "    duration_frame = video_info[8][0][0]\n",
    "    fps = video_info[9][0][0]\n",
    "    generateNode(video_info, USR_WIN, USR_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Task of Classification\n",
    "* Mainly extract the nodes, and have a list of objects to represent the nodes.\n",
    "* each node should contain as much information as possible\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
